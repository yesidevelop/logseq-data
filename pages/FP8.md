- An **FP8 model** refers to ==a machine learning (typically deep learning or AI) model that uses the **8-bit floating point (FP8)** data format for its numerical computations and data storage==. This low-precision format uses significantly fewer bits than traditional formats like 32-bit floating point (FP32) or even 16-bit (FP16/BF16), primarily to accelerate computation, reduce memory usage, and improve energy efficiency without significant loss in model accuracy